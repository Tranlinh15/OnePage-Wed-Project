"use server";

export async function askChatbot(message: string, history: any[] = []) {
  const apiKey = process.env.GROQ_API_KEY;

  if (!apiKey) return { error: "Meow! Ch∆∞a c√≥ API Key r·ªìi sen ∆°i!" };

  const endpoint = "https://api.groq.com/openai/v1/chat/completions";
  const modelName = "llama-3.3-70b-versatile";

  try {
    const messages = history.map((msg) => ({
      role: msg.role === "assistant" ? "assistant" : "user",
      content: msg.content,
    }));

    // üëá SYSTEM PROMPT: T·∫°o t√≠nh c√°ch Cute
    messages.unshift({
      role: "system",
      content:
        "B·∫°n l√† OPPM Bot, m·ªôt tr·ª£ l√Ω qu·∫£n l√Ω d·ª± √°n b·∫°n c√≥ ki·∫øn th·ª©c t·ªët v·ªÅ vi·ªác qu·∫£n tr·ªã d·ª± √°n, qu·∫£n l√Ω nh√¢n s·ª±, th·ªùi gian. H√£y gi√∫p ng∆∞·ªùi d√πng qu·∫£n l√Ω d·ª± √°n c·ªßa h·ªç m·ªôt c√°ch hi·ªáu qu·∫£ v√† ƒë√°ng y√™u nh·∫•t c√≥ th·ªÉ! Khi tr·∫£ l·ªùi h√£y xu·ªëng d√≤ng ƒë·ªÉ ng∆∞·ªùi h·ªèi d·ªÖ nh√¨n",
    });

    messages.push({ role: "user", content: message });

    const response = await fetch(endpoint, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${apiKey}`,
      },
      body: JSON.stringify({
        messages: messages,
        model: modelName,
        temperature: 0.7,
        max_tokens: 1000,
      }),
    });

    if (!response.ok) throw new Error(`API Error: ${response.status}`);

    const data = await response.json();
    return {
      text:
        data.choices[0]?.message?.content ||
        "Hic, m√¨nh ng·ªß g·∫≠t ch√∫t, b·∫°n h·ªèi l·∫°i nha!",
    };
  } catch (error) {
    console.error("Chatbot Error:", error);
    return { error: "M·∫°ng b·ªã lag r·ªìi, th·ª≠ l·∫°i sau nh√©! üòø" };
  }
}
